{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/triniroca/Desktop/STATS_FINAL/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import kagglehub\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/triniroca/.cache/kagglehub/datasets/ayoubcherguelaine/company-documents-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"ayoubcherguelaine/company-documents-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in the dataset:\n",
      "CompanyDocuments\n",
      "company-document-text.csv\n"
     ]
    }
   ],
   "source": [
    "#seeinG What files are within the dataset\n",
    "files = os.listdir(path)\n",
    "print(\"Files in the dataset:\")\n",
    "for file in files:\n",
    "    print(file)\n",
    "# Reading the CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (2676, 3)\n",
      "dataframe columns: Index(['text', 'label', 'word_count'], dtype='object')\n",
      "First few rows of the dataframe:                                                 text          label  \\\n",
      "0  order id  10718 shipping details  ship name  k...  ShippingOrder   \n",
      "1  invoice order id  10707 customer id  arout ord...        invoice   \n",
      "2  order id  10448 shipping details  ship name  r...  ShippingOrder   \n",
      "3  invoice order id  11068 customer id  queen ord...        invoice   \n",
      "4  order id  10656 shipping details  ship name  g...  ShippingOrder   \n",
      "\n",
      "   word_count  \n",
      "0         120  \n",
      "1          66  \n",
      "2          96  \n",
      "3          68  \n",
      "4         109  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(path, \"company-document-text.csv\"))\n",
    "\n",
    "print(\"Dataframe shape:\", df.shape)\n",
    "print(\"dataframe columns:\", df.columns)\n",
    "print(\"First few rows of the dataframe:\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/preprocessing.py\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess text by converting to lowercase, removing special characters, and normalizing spaces.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters and numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalize spaces\n",
    "    return text\n",
    "\n",
    "def load_and_preprocess_data(dataset_path):\n",
    "    \"\"\"Load the dataset, preprocess the text, and split into train/test sets.\"\"\"\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
    "    X = df['cleaned_text'].tolist()\n",
    "    y = df['label'].tolist()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test, df\n",
    "\n",
    "def vectorize_text(X_train, X_test, max_features=5000):\n",
    "    \"\"\"Convert text to TF-IDF features.\"\"\"\n",
    "    vectorizer = TfidfVectorizer(max_features=max_features, stop_words='english', ngram_range=(1, 2))\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "    return X_train_tfidf, X_test_tfidf, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample cleaned text:\n",
      " order id shipping details ship name kniglich essen ship address maubelstr ship city brandenburg ship region western europe ship postal code ship country germany customer details customer id koene customer name kniglich essen employee details employee name nancy davolio shipper details shipper id shipper name federal shipping order details order date shipped date products product queso manchego la pastora quantity unit price total product pavlova quantity unit price total product inlagd sill quantity unit price total product tarte au sucre quantity unit price total total price total price\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing function for classification\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters and numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalize spaces\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
    "print(\"Sample cleaned text:\\n\", df['cleaned_text'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " ShippingOrder       1.00      1.00      1.00       174\n",
      "       invoice       1.00      1.00      1.00       171\n",
      "purchase Order       1.00      1.00      1.00       151\n",
      "        report       1.00      1.00      1.00        40\n",
      "\n",
      "      accuracy                           1.00       536\n",
      "     macro avg       1.00      1.00      1.00       536\n",
      "  weighted avg       1.00      1.00      1.00       536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare data\n",
    "X = df['cleaned_text'].tolist()\n",
    "y = df['label'].tolist()\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert text to TF-IDF features\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train SVM classifier\n",
    "classifier = SVC(kernel='linear')\n",
    "classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = classifier.predict(X_test_tfidf)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Extraction\n",
    "def extract_invoice_info(text):\n",
    "    info = {}\n",
    "    info['Invoice Number'] = re.search(r'order id\\s+(\\d+)', text, re.IGNORECASE).group(1) if re.search(r'order id\\s+(\\d+)', text) else \"Not found\"\n",
    "    info['Invoice Date'] = re.search(r'order date\\s+(\\d{4}-\\d{2}-\\d{2})', text, re.IGNORECASE).group(1) if re.search(r'order date\\s+(\\d{4}-\\d{2}-\\d{2})', text) else \"Not found\"\n",
    "    info['Due Date'] = re.search(r'due date\\s+(\\d{4}-\\d{2}-\\d{2})', text, re.IGNORECASE).group(1) if re.search(r'due date\\s+(\\d{4}-\\d{2}-\\d{2})', text) else \"Not found\"\n",
    "    info['Issuer Name'] = re.search(r'from\\s+([A-Za-z\\s]+)', text, re.IGNORECASE).group(1) if re.search(r'from\\s+([A-Za-z\\s]+)', text) else \"Northwind Traders\"\n",
    "    info['Recipient Name'] = re.search(r'customer id\\s+(\\w+)', text, re.IGNORECASE).group(1) if re.search(r'customer id\\s+(\\w+)', text) else \"Not found\"\n",
    "    info['Total Amount'] = re.search(r'TotalPrice\\s+\\$?(\\d+\\.?\\d*)', text, re.IGNORECASE).group(1) if re.search(r'TotalPrice\\s+\\$?(\\d+\\.?\\d*)', text) else \"Not found\"\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Category: invoice\n",
      "Result: {'Invoice Number': '10707', 'Invoice Date': '2017-10-16', 'Due Date': 'Not found', 'Issuer Name': 'Northwind Traders', 'Recipient Name': 'arout', 'Total Amount': 'Not found'}\n"
     ]
    }
   ],
   "source": [
    "# Step 4: End-to-End\n",
    "def process_document(text):\n",
    "    cleaned_text = preprocess_text(text)\n",
    "    text_tfidf = vectorizer.transform([cleaned_text])\n",
    "    category = classifier.predict(text_tfidf)[0]\n",
    "    if category.lower() == 'invoice':\n",
    "        return extract_invoice_info(text)\n",
    "    return None\n",
    "\n",
    "# Test\n",
    "sample_text = df['text'].iloc[1]\n",
    "result = process_document(sample_text)\n",
    "print(\"Predicted Category:\", classifier.predict(vectorizer.transform([preprocess_text(sample_text)]))[0])\n",
    "print(\"Result:\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
